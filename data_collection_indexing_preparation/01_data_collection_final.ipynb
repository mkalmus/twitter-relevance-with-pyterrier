{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: Data Collection\n",
    "This notebook contains the code we used to collect data for the Twitter Information Retrieval System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install requests_oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1638922079641,
     "user": {
      "displayName": "Michael Kalmus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0ctc0Rmv08ljnJF9_jYxXnpRUmXLNsmVmWJGA=s64",
      "userId": "08396629992174191279"
     },
     "user_tz": 300
    },
    "id": "wg9p1lReZydk"
   },
   "outputs": [],
   "source": [
    "from requests_oauthlib import OAuth1\n",
    "import json\n",
    "import requests\n",
    "from collections import Counter\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You will need to enter a bearer token for Twitter's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1638922333960,
     "user": {
      "displayName": "Michael Kalmus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0ctc0Rmv08ljnJF9_jYxXnpRUmXLNsmVmWJGA=s64",
      "userId": "08396629992174191279"
     },
     "user_tz": 300
    },
    "id": "V4fwJX8Wb90a"
   },
   "outputs": [],
   "source": [
    "BEARER_TOKEN = 'YOUR_BEARER_TOKEN'\n",
    "\n",
    "CACHE_FILENAME = '../tweets_cache_tweets.json'\n",
    "AUTHOR_PATH = '../all_author_df.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1638922335555,
     "user": {
      "displayName": "Michael Kalmus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0ctc0Rmv08ljnJF9_jYxXnpRUmXLNsmVmWJGA=s64",
      "userId": "08396629992174191279"
     },
     "user_tz": 300
    },
    "id": "mrY5E13c1Vdv"
   },
   "outputs": [],
   "source": [
    "def load_authors(new=False):\n",
    "    if AUTHOR_PATH and new==False:\n",
    "        print('Loading created author file')\n",
    "    elif not AUTHOR_PATH or new==True:\n",
    "        print('Creating new author file')\n",
    "        with open(AUTHOR_PATH, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(\n",
    "                ['author_handle', 'author_id', 'author_bio', 'author_name', 'following_count','follower_count'])\n",
    "    authors = pd.read_csv(AUTHOR_PATH)\n",
    "    return authors\n",
    "\n",
    "def open_cache():\n",
    "    try:\n",
    "        cache_file = open(CACHE_FILENAME, 'r')\n",
    "        cache_contents = cache_file.read()\n",
    "        cache_dict = json.loads(cache_contents)\n",
    "        cache_file.close()\n",
    "    except:\n",
    "        cache_dict = {}\n",
    "    return cache_dict\n",
    "\n",
    "def save_cache(cache_dict):\n",
    "    dumped_json_cache = json.dumps(cache_dict)\n",
    "    fw = open(CACHE_FILENAME,\"w\")\n",
    "    fw.write(dumped_json_cache)\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 146,
     "status": "ok",
     "timestamp": 1638922339447,
     "user": {
      "displayName": "Michael Kalmus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0ctc0Rmv08ljnJF9_jYxXnpRUmXLNsmVmWJGA=s64",
      "userId": "08396629992174191279"
     },
     "user_tz": 300
    },
    "id": "Ri4HqCYRaYWf"
   },
   "outputs": [],
   "source": [
    "#Created code with help from https://github.com/twitterdev/Twitter-API-v2-sample-code/blob/main/Sampled-Stream/sampled-stream.py\n",
    "\n",
    "def create_stream_url():\n",
    "    return \"https://api.twitter.com/2/tweets/sample/stream?tweet.fields=lang&expansions=author_id&user.fields=description,name,public_metrics\"\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {BEARER_TOKEN}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2SampledStreamPython\"\n",
    "    return r\n",
    "\n",
    "def connect_to_endpoint(url, n_users): \n",
    "    response = requests.request(\"GET\", url, auth=bearer_oauth, stream=True)\n",
    "    output_file = open(AUTHOR_PATH, 'a')\n",
    "    writer = csv.writer(output_file)\n",
    "    \n",
    "    count = 0\n",
    "    for response_line in response.iter_lines():\n",
    "        if count >= n_users:\n",
    "            output_file.close()\n",
    "            sys.exit('Got all users')\n",
    "        if response_line:\n",
    "            json_response = json.loads(response_line)\n",
    "            if json_response['data']['lang'] == 'en' and not json_response['data']['text'].startswith(('RT', '@')):\n",
    "                author_handle = json_response['includes']['users'][0]['username']\n",
    "                author_desc = json_response['includes']['users'][0]['description']\n",
    "                author_name = json_response['includes']['users'][0]['name']\n",
    "                author_tweet_count = json_response['includes']['users'][0]['public_metrics']['tweet_count']\n",
    "                followers = json_response['includes']['users'][0]['public_metrics']['followers_count']\n",
    "                following = json_response['includes']['users'][0]['public_metrics']['following_count']\n",
    "                author_id = json_response['data']['author_id']\n",
    "                #['author_handle', 'author_id', 'author_bio', 'author_name', 'following_count','follower_count']\n",
    "                writer.writerow([author_handle, author_id, author_desc, author_name, followers, following])\n",
    "                count += 1  \n",
    "    return None\n",
    "\n",
    "def run_stream(n_users):\n",
    "    url = create_stream_url()\n",
    "    timeout = 0\n",
    "    while True:\n",
    "        connect_to_endpoint(url, n_users=n_users)\n",
    "        timeout += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1638922339591,
     "user": {
      "displayName": "Michael Kalmus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0ctc0Rmv08ljnJF9_jYxXnpRUmXLNsmVmWJGA=s64",
      "userId": "08396629992174191279"
     },
     "user_tz": 300
    },
    "id": "mnhAAqUhcpMJ"
   },
   "outputs": [],
   "source": [
    "def create_user_url(user_id, max_results):\n",
    "    tweet_fields = \"tweet.fields=lang,text,referenced_tweets,public_metrics,in_reply_to_user_id,author_id,entities\"\n",
    "    max_results = \"max_results={}\".format(max_results)\n",
    "    return \"https://api.twitter.com/2/users/{}/tweets?&{}&{}\".format(user_id,tweet_fields, max_results)\n",
    "\n",
    "def get_user_tweets(author_id):\n",
    "    filtered_tweets = []\n",
    "    author_url = create_user_url(user_id=author_id, max_results=50)\n",
    "    response = requests.get(author_url, auth=bearer_oauth)\n",
    "    resp_json = json.loads(response.text)\n",
    "    try:\n",
    "        user_tweet_data = resp_json['data']\n",
    "    except:\n",
    "        return filtered_tweets\n",
    "\n",
    "    return user_tweet_data\n",
    "\n",
    "def create_user_bio_url(user_id):\n",
    "    user_fields = \"user.fields=description,public_metrics\"\n",
    "    return \"https://api.twitter.com/2/users?ids={}&{}\".format(user_id, user_fields)\n",
    "                                                                       \n",
    "    \n",
    "def get_user_bio(author_id):\n",
    "    bios = []\n",
    "    author_bio_url = create_user_bio_url(user_id=author_id)\n",
    "    response = requests.get(author_bio_url, auth=bearer_oauth)\n",
    "    resp_json = json.loads(response.text)\n",
    "    try:\n",
    "        user_bio_data = resp_json['data'][0]\n",
    "    except:\n",
    "        return bios\n",
    "\n",
    "    return user_bio_data  \n",
    "\n",
    "def clean_all_tweets(tweet_cache):\n",
    "    clean_tweets_all = []\n",
    "    for user_tweets in tweet_cache.values():\n",
    "        for sample_tweet in user_tweets:\n",
    "            clean_tweet_dict = {}\n",
    "            try:\n",
    "                if sample_tweet['lang'] == 'en':\n",
    "                    if 'referenced_tweets' not in sample_tweet.keys():\n",
    "                        #remove links\n",
    "                        clean_text = re.sub(r'https?:\\/\\/\\S*', \"\", sample_tweet['text']).strip()\n",
    "                        #remove punctuation\n",
    "                        clean_text = clean_text.translate(str.maketrans('', '', string.punctuation))\n",
    "                        #remove one-word or one-character tweets\n",
    "                        if len(clean_text.split()) > 1:      \n",
    "                            clean_tweet_dict['text'] = clean_text\n",
    "                            clean_tweet_dict['author_id'] = sample_tweet['author_id']\n",
    "                            clean_tweets_all.append(clean_tweet_dict)\n",
    "            except:\n",
    "                continue\n",
    "    return clean_tweets_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1638922340487,
     "user": {
      "displayName": "Michael Kalmus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0ctc0Rmv08ljnJF9_jYxXnpRUmXLNsmVmWJGA=s64",
      "userId": "08396629992174191279"
     },
     "user_tz": 300
    },
    "id": "m9sf3znF6A24"
   },
   "outputs": [],
   "source": [
    "# #Create blank author file \n",
    "# all_author_df = load_authors(new=False)\n",
    "# #Get 10 random authors\n",
    "# run_stream(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10104,
     "status": "ok",
     "timestamp": 1638924055919,
     "user": {
      "displayName": "Michael Kalmus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0ctc0Rmv08ljnJF9_jYxXnpRUmXLNsmVmWJGA=s64",
      "userId": "08396629992174191279"
     },
     "user_tz": 300
    },
    "id": "6Ryk1Gmxb-KS",
    "outputId": "e1677155-cb35-49f5-8465-4bc1b8b10be2"
   },
   "outputs": [],
   "source": [
    "# New authors = authors that are in the author df but don't have tweets yet cached\n",
    "all_author_df = load_authors(new=False)\n",
    "tweet_cache = open_cache()\n",
    "\n",
    "all_author_df = all_author_df[~all_author_df.duplicated()]\n",
    "all_author_df['author_id'] = all_author_df['author_id'].astype(str)\n",
    "all_authors = list(all_author_df['author_id'])\n",
    "print(f\"Loaded data for {len(all_author_df)} authors\")\n",
    "new_authors = [str(author) for author in all_authors if str(author) not in tweet_cache.keys()]\n",
    "print(f\"Found {len(new_authors)} new authors in df\")\n",
    "\n",
    "#Get tweets for authors we don't have tweets for yet\n",
    "if len(new_authors) > 0:\n",
    "    for new_author_id in new_authors:\n",
    "        author_tweets = get_user_tweets(author_id=new_author_id)\n",
    "        tweet_cache[new_author_id] = author_tweets\n",
    "\n",
    "save_cache(tweet_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 2903,
     "status": "ok",
     "timestamp": 1638924743026,
     "user": {
      "displayName": "Michael Kalmus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0ctc0Rmv08ljnJF9_jYxXnpRUmXLNsmVmWJGA=s64",
      "userId": "08396629992174191279"
     },
     "user_tz": 300
    },
    "id": "Kkum_mnp6kCL"
   },
   "outputs": [],
   "source": [
    "clean_tweets_all = clean_all_tweets(tweet_cache=tweet_cache)\n",
    "tweet_df = pd.DataFrame(clean_tweets_all)\n",
    "tweet_df_clean = tweet_df.drop_duplicates(keep=\"first\")\n",
    "authors_with_tweets = tweet_df_clean['author_id'].unique()\n",
    "author_df_filtered = all_author_df[all_author_df['author_id'].isin(authors_with_tweets)]\n",
    "author_df_filtered = author_df_filtered.reset_index(drop=True).drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1638925075744,
     "user": {
      "displayName": "Michael Kalmus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0ctc0Rmv08ljnJF9_jYxXnpRUmXLNsmVmWJGA=s64",
      "userId": "08396629992174191279"
     },
     "user_tz": 300
    },
    "id": "0gFuK3bHmGj4"
   },
   "outputs": [],
   "source": [
    "def update_author_info(dataset):\n",
    "    id = []\n",
    "    name = []\n",
    "    followers = []\n",
    "    following = []\n",
    "    count = 1\n",
    "    count_a = 0\n",
    "    count_b = 100\n",
    "\n",
    "    for i in range(0,len(dataset)+1):\n",
    "        ids = dataset['author_id'][count_a:count_b]\n",
    "        converted_list = [str(element) for element in ids]\n",
    "        joined_string = \",\".join(converted_list)\n",
    "\n",
    "        author_bio_url = create_user_bio_url(joined_string)\n",
    "        response = requests.get(author_bio_url, auth=bearer_oauth)\n",
    "        resp_json = json.loads(response.text)\n",
    "        count += 1\n",
    "\n",
    "        for j in range(0, len(resp_json['data'])):\n",
    "            id.append(resp_json['data'][j]['id'])\n",
    "            name.append(resp_json['data'][j]['name'])\n",
    "            followers.append(resp_json['data'][j]['public_metrics']['followers_count'])\n",
    "            following.append(resp_json['data'][j]['public_metrics']['following_count'])\n",
    "\n",
    "\n",
    "        if count_b > len(dataset):\n",
    "            break\n",
    "        elif count >= 1:\n",
    "            count_a += 100\n",
    "            count_b += 100\n",
    "        else:\n",
    "            count_a = count_a\n",
    "            count_b = count_b\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "      {\n",
    "        'author_id': id,\n",
    "        'author_name': name,\n",
    "        'followers_count': followers,\n",
    "        'following_count': following\n",
    "      }\n",
    "    )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 19429,
     "status": "ok",
     "timestamp": 1638925179014,
     "user": {
      "displayName": "Michael Kalmus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi0ctc0Rmv08ljnJF9_jYxXnpRUmXLNsmVmWJGA=s64",
      "userId": "08396629992174191279"
     },
     "user_tz": 300
    },
    "id": "k_thyt5eV0Jw"
   },
   "outputs": [],
   "source": [
    "author_df_updated = update_author_info(author_df_filtered)\n",
    "\n",
    "author_df_new = x.merge(author_df_filtered[['author_id', 'author_bio', 'handle']], on=\"author_id\")\n",
    "author_df_new = author_df_new[['handle', 'author_id', 'author_bio', 'author_name', 'following_count', 'followers_count']]\n",
    "author_df_new.columns = ['author_handle', 'author_id', 'author_bio', 'author_name', 'following_count','follower_count']\n",
    "tweet_df_new = tweet_df_clean[tweet_df_clean['author_id'].isin(list(author_df_new['author_id']))]\n",
    "\n",
    "tweet_df_new.to_csv(data_path + '../all_tweets_updated.csv', index=True)\n",
    "author_df_new.to_csv(data_path + '../all_author_df.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5hIR1RpVgZC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_collection_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
